session 1

=====>Why Docker?
  What problem does Docker solve? 
- Docker solves the problem of having identical environments across various stages of development and having isolated environments for your individual applications.
- Environment setup and management is a tedious task in every project.
- Docker provides a solution to this problem with containerization.
- Earlier, we used to create virtual machines, and each VM had an OS which took a lot of space and made it heavy.Now in docker container’s case, you have a single OS, and the resources are shared between the containers. 

------------------------
===>What is containerization?
- Containerization means, that your application runs in an isolated container, that is an explicitly defined, reproducable and portable environment. 
- A container of an app is the app’s operating environment in our computing scenario. With Docker you ship the operating environment along with your application.
- One of the main benefits of using Docker, and container technology, is the portability of applications. It’s possible to spin up an application on-premises or in a public cloud environment in a matter of minutes.

===>Containers vs Virtual Machines
- Terms “Containers” and “Virtual Machines” are often used interchangeably, however, this is often a misunderstanding. But, both are just different methods to provide Operating System Virtualization.

- Standard virtual machines:
---------------------------
-Virtualization is a technique of importing a guest os on the top of host os.
- This technique is revolution in the beginning because Developers run the different application in different vms all running on same host whereas virtualization supported for a single server to run many standalone operating systems as virtual guests.
- Include a full Operating System, OS Packages and if required, few applications. This is made possible by a Hypervisor which provides hardware virtualization to the virtual machine. 

Host os=> Hypervisor=>(Guest os1,Guest os2....)=>(Bin& Lib, Bin & Lib 2.....)=>(App1,App2,.....)

- They take a physical server and provide a fully functional operating environment that shares those physical resources with other virtual machines.
- This eliminate the need of extra h/w resource and enable the backup allowing the the recovery in failure conditions

---> Advantages

   1.Multiple OS in the same machine
   2.Easy Maintainance and Recovery
   3.Lower total cost of Ownership

---> Disadvantages

   1.Multiple VMs Lead to unstable performance
   2.Hypervisors are not as efficient as a host os
   3.Long Boot up process (Approximate 1 minute)
   4.This is using the host system resources
   5.This is very critical in case of real time applications where fast processing is required. 
   6.scaling the no of vms is tedious and costly affiar

- Containers:
---------------------------
- Similar to virtual machines except that Containers are not full operating systems. They only include the necessary OS Packages and Applications.In other words, Contairnerization is Just Virtualization at OS Level 
- They do not generally contain a full operating system or hardware virtualization, that’s why these are “lightweight”.Binaries and Libraries of the containers are on the host kernel which makes processing and execution very fast

Host os=>Container Engine=>(Bin& Lib, Bin & Lib 2.....) =>(App1,App2)

- They are used to isolate a running process within a single host to ensure that the isolated processes cannot interact with other processes within that same system. 
- Containers sandbox processes from each other
- Docker enables creating and working with Containers as easy as possible.

- Virtualization brings the abstraction at h/w where as Contairnerization brings abstraction to software

--->  Advantages

	1.Containers on same os kernel are lighter and smaller
	2.Better Resource utilization Compared to VMS
	3.Short Boot up process (1/20th of second )

---------------------------

Which of the below option is incorrect ?

1. Contairnerization  is replacing Virtualization 
2. Contairnerization brings process level isolation
3. Hypervisors Manage the VMS.

2.What is  docker ?
=====================
Docker is a container management service.
The keywords of Docker are develop, ship and run anywhere.
The whole idea of Docker is for developers to easily develop applications, ship them into containers which can then be deployed anywhere.
- Docker is a container management service.
- The keywords of Docker are develop, ship and run anywhere.
- The whole idea of Docker is for developers to easily develop applications, ship them into containers which can then be deployed anywhere.
- It envelopes the application along with all other elements like external libraries and other such dependencies which are required to run the application into a single package smoothly.
- It is an open source which means that anyone can add features and functionalities to meet their needs thus contribute towards the betterment of the tool.


3.Features of Docker
====================

=>Docker has the ability to reduce the size of development by providing a smaller footprint of the operating system via containers.

=>With containers, it becomes easier for teams across different units, such as development, QA and Operations to work seamlessly across applications.

=>You can deploy Docker containers anywhere, on any physical and virtual machines and even on the cloud.

=>Since Docker containers are pretty lightweight, they are very easily scalable.

---------------------------
===> Features of Docker
- Docker has the ability to reduce the size of development by providing a smaller footprint of the operating system via containers.
-With containers, it becomes easier for teams across different units, such as development, QA and Operations to work seamlessly across applications.
-You can deploy Docker containers anywhere, on any physical and virtual machines and even on the cloud.
-Since Docker containers are pretty lightweight, they are very easily scalable.

===Common Docker Use Cases
(1)Configuration Simplification: 
- Docker can run on any platform with the help of its configuration without the actual overhead of a virtual machine.
- It allows you to put the configuration file into the code and pass environment variables to cater to different environments. So that one docker image could be used in the different environment.

(2)Code Management: The code travels through a different environment in its journey from development to production.
- Each environment is having slight variation than the other. Docker eliminates this difference by providing a consistent environment, making the development and coding so much more comfortable.
- Docker images being immutable they come with the advantage of having zero change in application environment from dev to production.

(3)Improved Development Productivity: The two essential objectives in the development ecosystem, is to have the development environment replicate as close as possible to the production environment and next goal to get quality code delivered as soon as possible.
- Docker allows the code to run in a container which reflects the production environment and unlike VM, docker has lesser overhead memory capacity wise which helps several services to run.

(4)Isolation of Applications: There are cases where application isolation may be needed for example API servers which require different apache and a different set of dependencies.
- Running API servers under different containers is much better way out.

(5)Debugging Capabilities: Docker provides numerous tools that work well with containers, with the ability to insert checkpoints within containers and also different containers which are quite essential while testing applications.

(6)Rapid Deployment: Docker containers can be created quite quickly which achieved as containers are not booting up an OS but just running the application.
- Once set, they give you peace that once the code has worked, it will work in all environment.

------------------------
--->Docker Editions:Docker is available in two editions:
(1)Community Edition (CE)
(2)Enterprise Edition (EE)

(1)Docker Community Edition (CE) is ideal for individual developers and small teams looking to get started with Docker and experimenting with container-based apps.

(2)Docker Enterprise Edition (EE) is designed for enterprise development and IT teams who build, ship, and run business critical applications in production at scale.

===> Docker installation methods
- Generally, there are three main Docker installation methods, the choice of which depends on the situation and environment, as explained below.
(1)Using the Docker repositories: – Easy to install and upgrade method recommended for most online installations.
(2)Manual download, installation, and upgrades: – suitable for offline computers that have no access to internet
(3)Using automated scripts: for development and testing environments.


--->Installation using the Docker repositories
(1)Docker for Mac - It allows one to run Docker containers on the Mac OS.
(2)Docker for Linux - It allows one to run Docker containers on the Linux OS.
(3)Docker for Windows - It allows one to run Docker containers on the Windows OS.

-Docker Engine - It is used for building Docker images and creating Docker containers.
-Docker Hub - This is the registry which is used to host various Docker images.
-Docker Compose - This is used to define applications using multiple Docker containers.

------------------------
===>Installation of Docker on windows?
- Refer this site :  https://docs.docker.com/toolbox/toolbox_install_windows/

- For windows we need to download Docker toolbox.
- To Check Installation: Open the Command Promt and check on the below mentined commands
1.docker version  :shows the version of docker
2.docker info     :gives the information of docker
-----------------------
Diff between docker toolbox and docker for windows
I. Docker tool box installation gives you the below things
1.Docker CE/EE
2.Docker Compose
3.Docker Machine: creates a VM . runs the lightweight Linux machine. 
4.VirtualBox: loads linux on non linux os like windows and mac. because docker loads in linux os.It is type2hypervisor and runs on all major platforms
5.Docker Quickstart terminal: creates a new server on docker maachine
6.kitematic: graphical tool that manages images

docker toolbox+docker machine==VirtualBox VM+docker installed
The first 3 are specific to docker

II. Docker for Windows/Mac
--No Virttualbox required . It uses hypervisor 1 that comes coded with the OS
   Windows uses Hyper-v
   MacOS uses Hyperkit
 It gives you below 3 things
1.Docker CE/EE
2.Docker Compose
3.Docker Machine

Docker Toolbox			Dockerfor Mac/win
----------------		--------------------
Need type 2 hypervisor		Need a type 1 hypervisor
windows 7+(Home edition is ok)	Win 10(pro,Ent,stu)
Docker deemon[remote]		docker deemon[local]
access 192.168.99.199		Any terminal you want
Might be faster			Might be slower
------------------------

Docker Basic Commands
=====================

Basic
: docker version
: docker -v 
: docker --version 
: docker info
: docker --help
: docker login

 docker search --filter=stars=3
he flag --limit is the maximum number of results returned by a search. This value could be in the range between 1 and 100. The default value of --limit is 25.

————————————
Images
: docker images                        To list the images
: docker images -q                     To list the images
: docker pull                          To pull tha image
: docker rmi                           To remove one or more iamges
: docker rmi $(docker images -q)       To remove all images

————————————
Containers
: docker ps                                                 shows only running cotainers(use -a for show all containers))
: docker ps -a                                              shows all containers
: docker rm <container-name>                                remove one or more containers
: docker rm $(docker ps -a -q)                              remove all containers
: docker run <image-name>                                   create a container from image (first time used to container)
: docker run -d <image-name>                                create a container from image in detached mode
: docker run -it <image-name> bash                          create a container from image in interactive mode
: docker start -i <container-name>                          To start the stoped container
: docker stop <container-name>                              To stop running container
: docker logs <container-name>                              To sess logs of contianer
: docker exec -it <container-name> bash                     To interact with container
: docker run --name a-centos -it centos bash                container will not be removed on exit
: docker run --name b-centos --rm -it centos bash           container will be removed on exit
  
————————————
System
: docker stats
: docker system df
: docker system prune (to stop all stoped containers)

Online practice for docker:

https://labs.play-with-docker.com/

===>Docker Basic Commands

-Verify docker version installed on the machine
: docker version
: docker --version
: docker -v

- Verify docker Engine Set-Up and details
: docker info

- List all Docker commands
docker

: docker --help
: docker login
: docker ps
: docker stats
————————————
===>Docker Architecture: Docker has the following Components:
(1)Docker Engine
(2)Docker Client
(3)Docker Registries
(4)Docker Objects

(1)Docker Engine
- core part of the whole Docker system
- It is a client-server application with these major components:
(1.1)Server: It is the docker daemon called dockerd. It can create and manage docker images. Containers, networks, etc.
(1.2)Rest API: It is used to instruct docker daemon what to do.
(1.3)Command Line Interface (CLI): It is a client which is used to enter docker commands.

(2)Docker Client
- Docker users can interact with Docker through a client. 
- When any docker commands runs, the client sends them to dockerd daemon, which carries them out. Docker API is used by Docker commands. Docker client can communicate with more than one daemon.

(3)Docker Registries
- It is the location where the Docker images are stored. It can be a public docker registry or a private docker registry. 
- Docker Hub is the default place of docker images, its stores’ public registry. 
- When you execute docker pull or docker run commands, the required docker image is pulled from the configured registry. 
- When you execute docker push command, the docker image is stored on the configured registry.
-Docker store allows you to buy and sell Docker images or distribute them for free.

===>Docker Environment :Combination of Docker Engine and Docker Objects

(4)Docker Objects
- When you are working with Docker, you use images, containers, volumes, networks; all these are Docker objects.

————————————
===>Docker Objects

(1)Images
- Docker images are read-only templates with instructions to create a docker container. 
- Docker image can be pulled from a Docker hub and used as it is, or you can add additional instructions to the base image and create a new and modified docker image. 
- You can create your own docker images also using a dockerfile. Create a dockerfile with all the instructions to create a container and run it; it will create your custom docker image.
- Docker image has a base layer which is read-only, and the top layer can be written. When you edit a dockerfile and rebuild it, only the modified part is rebuilt in the top layer.

(2)Containers
- After you run a docker image, it creates a docker container. 
- All the applications and their environment run inside this container. You can use Docker API or CLI to start, stop, delete a docker container.
- E.g:Basic Hello World
docker container run hello-world
or
docker run hello-world

-->To run a ubuntu docker container: docker run -i -t ubuntu /bin/bash

(3)Volumes
- The persisting data generated by docker and used by Docker containers are stored in Volumes. They are completely managed by docker through docker CLI or Docker API. 
- Volumes work on both Windows and Linux containers. Rather than persisting data in a container’s writable layer, it is always a good option to use volumes for it. 
- Volume’s content exists outside the lifecycle of a container, so using volume does not increase the size of a container.
- You can use -v or –mount flag to start a container with a volume. 
- E.g :In this sample command, you are using xvolume volume with xxx container.

docker run -d --name xxx  -v xvolume:/app nginx:latest

(4)Networks
-Docker networking is a passage through which all the isolated container communicate. 
-There are mainly five network drivers in docker:
(4.1)Bridge: It is the default network driver for a container. You use this network when your application is running on standalone containers, i.e. multiple containers communicating with same docker host.
(4.2)Host: This driver removes the network isolation between docker containers and docker host. It is used when you don’t need any network isolation between host and container.
(4.3)Overlay: This network enables swarm services to communicate with each other. It is used when the containers are running on different Docker hosts or when swarm services are formed by multiple applications.
(4.4)None: This driver disables all the networking.
(4.5)macvlan: This driver assigns mac address to containers to make them look like physical devices. The traffic is routed between containers through their mac addresses. This network is used when you want the containers to look like a physical device, for example, while migrating a VM setup.

---->Registry & Repository
-A repository is a hosted collection of tagged images that together create the file system for a container.

-A registry is a host -- a server that stores repositories and provides an HTTP API for managing the uploading and downloading of repositories.
-Docker.com hosts its own index to a central registry which contains a large number of repositories. Having said that, the central docker registry does not do a good job of verifying images and should be avoided if you're worried about security.

————————————
Images (Documentation: https://docs.docker.com/engine/reference/commandline/docker/)

--->Lists the images available locally
docker images 
or
docker image list
or
docker image ls

Notes:
- The TAG refers to a particular snapshot of the image 
- IMAGE ID is the corresponding unique identifier for that image.
- you can think of an image akin to a git repository

--->Where are Images Stored
(1) Registries (e.g. docker hub)
(2) Can be stored locally or remote

--->Pulling an image from the repository
docker pull ubuntu
docker pull ubuntu:18.04 

Notes:
- images can be committed with changes and have multiple versions.If you don't provide a specific version number, the client defaults to latest

---> List the full length image IDs 
docker images --no-trunc

--->List images by name and tag 
docker images java or docker images ubuntu

- If both REPOSITORY and TAG are provided, only images matching that repository and tag are listed.
- If nothing matches REPOSITORY, the list is empty.(E.g. docker images java:0)

--->fetching an image with a version
docker images ubuntu:18.04

--->searching for an image 
- -There are tens of thousands of images available on Docker Hub. You can also search for images directly from the command line using docker search.
docker search ubuntu)

--->To find out more about a Docker image, run 
docker inspect ubuntu

Notes:
- To get a new Docker image you can either get it from a registry (such as the Docker Hub) or create your own. 
: docker images -q
: docker images -f “dangling=false”
: docker images -f “dangling=false” -q
: docker pull
: docker push
: docker rmi
: docker run : Running an image(E.g. docker run ubuntu)
: docker rmi -f ubuntu: Remove an Image

--->Types of Images:
(1)Base images :images that have no parent image, usually images with an OS like ubuntu, busybox or debian.
(2)Child images : images that build on base images and add additional functionality.

--->Another categorization:
(1)Official images :images that are officially maintained and supported by the folks at Docker. These are typically one word long. In the list of images above, the python, ubuntu, busybox and hello-world images are official images.

(2)User images are images created and shared by users like you and me. They build on base images and add additional functionality. Typically, these are formatted as user/image-name.



====================================================================
session 2

To create a container from image only first time
===================================================
docker run --name a-centos -it centos 

docker start a-centos
docker stop a-centos
docker rm a-centos
docker logs a-centos
docker ps
docker ps -a
docker exec -it a-centos bash
docker rm $(docker ps -a -q)


docker run --name a-centos -it centos bash

docker run --name b-centos -it centos bash

docker network inspect bridge

docker exec -it a-centos bash

# ping 172.17.0.3



docker internall uses networking concepts
==========================================
bridge
host
none



mysql
============
docker run --name p-mysql -e MYSQL_ROOT_PASSWORD=pass123 -d mysql

docker run --name p-mysql -e MYSQL_ROOT_PASSWORD=pass123 -p 3232:3306 -d mysql:5.6


docker logs p-mysql

docker exec -it p-mysql bash

#mysql -uroot -pmypass

mysql> show databases


======================================
web servers :httpd    default port :80
            :nginx    default port :80
            :mysql    default port :3306
            :mongodb  default port :27017   

demo -port forwardisation: 
$docker run -p 6666:80 -d httpd

docker run --name a-nginx -p  1111:80 -d nginx
docker run --name b-nginx -p  2222:80 -d nginx
docker run --name c-nginx -p  3333:80 -d nginx


docker exec -it a-nginx bash
echo "<h1>Hello A-NgInx Server </h1>" > /usr/share/nginx/html/index.html

docker exec -it b-nginx bash
echo "<h1>Hello B-NgInx Server </h1>" > /usr/share/nginx/html/index.html

docker exec -it c-nginx bash
echo "<h1>Hello C-NgInx Server </h1>" > /usr/share/nginx/html/index.html

session 03
===============================================
some shortcut commands

Command to stop all running container at once
docker stop $(docker ps -a -q)

command to remove all containers
docker rm $(docker ps -a -q)

command to remove all images
docker rmi $(docker images -q)

========================================
Activity: To create image from running container (docker commit)
We want to create a simple web application like hello, and people should be able to pull your app from dock hub

step 1:
docker run --name a-httpd -p 1111:80 -d httpd

step 2:change the contents of html file
docker exec -it a-httpd bash

echo "<h1>Hello Welcome To Custom Apache Image</h1>" > /usr/local/apache2/htdocs/index.html

--> now refresh the page on 1111 we should get the changes
-->In case you are running on docker desktop use http://localhost:1111

exit

step 3: commit the changes
$docker commit -m 'Index File Content Changed' -a 'kathir <kathirkathir2006@gmail.com>' a-httpd kathirkathir2006/a-httpd

--docker login through browser
username :kathirkathir2006
password :password@123

docker push kathirkathir2006/a-httpd

---can be run on any machine
docker run --name b-apache -p 4545:80 -d kathirkathir2006/apache:1.1

Activity : creating image from scratch (docker build)
for this we use Dockerfile : 
A text file with instructions to build image
Automation of Docker Image Creation

FROM           :Base Image    
MAINTAINER     :Author Name
ENV            :Environment variable
ADD            :ADD the files while buiding the image
RUN            :To install libraries/packages (executed while building the image)
ENTRYPOINT     :Executed at run time and we can not override the commands
CMD            :Executed at run time and we can override by passing command line argument


Step 1 : Create a file named Dockerfile
Step 2 : Add instructions in Dockerfile
Step 3 : Build dockerfile to create image
Step 4 : Run image to create container

Example  :Dockerfile
Step 1 : Create a file named Dockerfile

$vi Dockerfile

Step 2 : Add instructions in Dockerfile
copy the below code

FROM ubuntu
MAINTAINER kathirkathir2006 <kathirkathir2006m@gmail.com>
RUN apt-get update

CMD ["echo", "Hello World..! from my first docker image1"]
CMD ["echo", "Hello World..! from my first docker image2"]
CMD ["echo", "Hello World..! from my first docker image3"]
CMD ["echo", "Hello World..! from my first docker image4"]

Note: CMD can be written multiple times but the last one will be called

press esc
save it using :save Dockerfile
then type :wq enter

Step 3 : Build dockerfile to create image
$ docker build -t chhayanikam01/a-ubuntu:1.1 .

here -t is for tagging image
dot is for the current dir where Dockerfile is created
You may createmultiple images from the dockerfile
$ docker build -t b-ubuntu:1.1 .

step 4: you can optionally push the image to docker hub
docker push kathirkathir2006/a-ubuntu:1.1
Note:use docker login in case you are not logged in

step 5:
docker run kathirkathir2006/a-ubuntu:1.1

COMMANDS
: docker build directoryOfDocekrfile
: docker build -t ImageName:Tag directoryOfDocekrfile
: docker run imageid 
--------------------------------------
Using ENTRYPOINT
modify the Dockerfile as below

FROM ubuntu
MAINTAINER Chhaya Nikam <chhaya.nikam@gmail.com>
RUN apt-get update

ENTRYPOINT ["echo", "Hello World..! from my first docker iamge1"]
ENTRYPOINT ["echo", "Hello World..! from my first docker iamge2"]
ENTRYPOINT ["echo", "Hello World..! from my first docker iamge3"]
ENTRYPOINT ["echo", "Hello World..! from my first docker iamge4"]

The main difference between CMD and ENTRYPOINT is ENTRYPOINT  allows appending new contents while running docker container

$ docker build -t testentry .
$ docker run testentry
$ docker run testentry "Hello friends"

CMD and ENTRYPOINT can also used in combinations

-------------------------------------------------
Example:

Docker file for MYSQL
=======================
# Derived from official mysql image (our base image)
FROM mysql
# Add a database
ENV MYSQL_DATABASE company
ENV MYSQL_ROOT_PASSWORD admin
ENV MYSQL_USER user1
ENV MYSQL_PASSWORD password
# Add the content of the sql-scripts/ directory to your image
# All scripts in docker-entrypoint-initdb.d/ are automatically
# executed during container startup
ADD script.sql /docker-entrypoint-initdb.d/


script.sql
===========
use company;
create table employee(id int primary key,name text,salary double);
insert into employee values(101,'RAM',10000.00);
insert into employee values(102,'RAHIM',20000.00);
insert into employee values(103,'DAVID',30000.00);
insert into employee values(104,'Jack',40000.00);

$ docker build -f dock -t p-mysql:1.0 .
$ docker images
$docker run --name a-mysql -d p-mysql:1.0
$docker exec -it a-mysql bash
#mysql -uroot -padmin

docker run --name a-mysql -p 3232:3306 -d mysql:1.0
==========================================

----------------------------------------------------------------------------------------
Docker File Spring Boot Java Application
================================================
FROM openjdk:8
ADD target/docker-spring-boot.jar docker-spring-boot.jar
EXPOSE 8080
ENTRYPOINT ["java","-jar","docker-spring-boot.jar"]


======>

docker build -t username/spring-docker-demo:1.1 .

docker login

docker push username/spring-docker-demo:1.1

----------------------------------------------------------------------


===========================================
Example: Commiting the Image in the container (mongodb)
--------------------------------------------
--->Downloading the Latest MongoDB Docker Image
docker pull mongo #Pulls the latest one
or 
docker pull mongo:4.0.4 #Pulls the specific version

--->Deploying an Instance of MongoDB as a Container
docker run --name mongodb mongo:4.0.4

--> To check out on the logs for the image
docker logs mongodb
(Displays entire information of the container while starting as well the confirguration details if it has started successfully)
-->docker start mongodb

--->Interacting with the MongoDB Docker Container with Basic Shell Operations
docker exec -it mongodb bash

-it: stands for interactive mode

--> To communication with mongodb
Example: mongo

--> Show databases
show dbs;

--> To create a database
use trainingdb;

--> Switch to database
trainingdb

--> To create a collection
db.departments.insert({name:'Admin'});
db.departments.insert({name:'Training'});
db.departments.insert({name:'Quality'});
db.departments.insert({name:'HR'});

-->Fetch the data
trainingdb.departments.find()

--->Modifications can be done and changes commited to container. To commit the changes in container
docker commit -m 'Created mongodb' -a "username<urmail@gmail.com>" 53ef5a2fbda8 my-mongodb:latest
or
docker commit 53ef5a2fbda8 my-mongodb:latest

--->To Tag the Image
docker tag my-mongodb:latest username/my-mongodb

--->To Push The Images
docker push username/my-mongodb

-->view the repository on Docker hub
https://cloud.docker.com/repository/list

===========================================
Example: Commiting the Image in the container (mysql)
--------------------------------------------
docker run --name my-mysql -it mysql:latest bash
--Try runnig the command: mysqld --version
docker login
docker commit -m "added mysql server" -a "mySQL Image Created" my-mysql lijishynu/my-mysql:latest
docker push username/my-mysql
https://cloud.docker.com/repository/list
	
------------------------------------------------------------------------------------------
Session 4
Linking Docker containers with Links
===========================================
example: wordpress+mysql linking

Links allow the containers to discover each other and securely transfer the information about one container to another container.

step 1: create a custom bridge network
docker network create p-network

verify: 
docker network ls

step 2:
docker run --name mysql02 --network p-network -e MYSQL_ROOT_PASSWORD=Password1234 -d mysql:5.6
verify: 
docker ps
docker images
docker inspect p-network

step 3:
docker run --name wordpress02 --network p-network --link mysql02 -p 1111:80 -e WORDPRESS_DB_HOST=mysql02:3306 -e WORDPRESS_DB_USER=root -e WORDPRESS_DB_PASSWORD=Password1234 -e WORDPRESS_DB_NAME=wordpress -e WORDPRESS_TABLE_PREFIX=wp_ -d wordpress

Note:It is added to same p-network , --link is used to link the container, def port 80 of mysql is exposed to 1111,
       -e is used for environment variable.
       instead of ip address we are using mysql container name,3306 is the port at which sql server is running, password1234 is provided to wordpress to connect to        mysql db, wordpress database will be created with the table name prefixed as wp_ , both the containers will start in detach mode because of -d

step 4: test
click the 1111 port
select eng language-->complete the form ---> Install wordpress

step 4:checking the tables are created in mysql. so lets move inside the mysql02 container.
docker exec -it mysql02 bash
mysql -uroot -pPassword1234
show databases
use wordpress;
show tables;

step 4: create a new post
 query the user_post table
 

exit;  ----------> comes out of the container

Note: In docker toolbox you can use the ip of the container
eg.
http://192.168.0.23:1111
or 
http://localhost:1111
When we do port forwardization we are making the image availaible to all.

internally the containers know each other by name
to make it globally (external)available should have a dns

step 4: stop the running containers
docker stop mysql02 wordpress02
